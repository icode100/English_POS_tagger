{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6813582,"sourceType":"datasetVersion","datasetId":3919443}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data preprocessing\nhere we obtain the data from the json file and then process it by adding start and end tokens to it and then define the vocabulary, sentence list and also the tags (or the state) corresponding to each observation (or words). These will be helpful for us in determining the parameters of **Hidden Markov Model later**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport json\nfrom collections import defaultdict,Counter\n\nwith open('/kaggle/input/annotated-dataset-for-pos-tagging/dev.json', 'r') as f:\n    json_data = f.read()\nwith open('/kaggle/input/annotated-dataset-for-pos-tagging/train.json','r') as f:\n    json_data = f.read()\n    \ndataset_1 = json.loads(json_data)\nfor item in dataset_1:\n    item['sentence'].insert(0,'<s>')\n    item['sentence'].append('</s>')\n    item['labels'].insert(0,'<s>')\n    item['labels'].append('</s>')\ndataset_2 = json.loads(json_data)\nfor item in dataset_2:\n    item['sentence'].insert(0,'<s>')\n    item['sentence'].append('</s>')\n    item['labels'].insert(0,'<s>')\n    item['labels'].append('</s>')\ndataset = dataset_1+dataset_2\nprint(f'length of dataset is {len(dataset)}')\n\nstate_tags = defaultdict(set)\nsentences = list()\nstate_seq = list()\nvocab = set()\ntags = set()\ntag_count = defaultdict(int)\nword_count = defaultdict(int)\ntag_zipped_words = list()\nfrom copy import deepcopy\nfor item in dataset:\n    sentences.append(item['sentence'])\n    state_seq.append(item['labels'])\n    tag_zipped_words.append(deepcopy(list(zip(item['sentence'],item['labels']))))\n    for word,count in list(Counter(item['sentence']).items()):\n        word_count[word]+=count\n    for tag,count in list(Counter(item['labels']).items()):\n        tag_count[tag]+=count   \n    vocab = vocab.union(set(item['sentence']))\n    tags = tags.union(set(item['labels']))\n    for i,word in enumerate(item['sentence']):\n        state_tags[word].add(item['labels'][i])","metadata":{"execution":{"iopub.status.busy":"2024-03-24T07:56:23.018445Z","iopub.execute_input":"2024-03-24T07:56:23.018998Z","iopub.status.idle":"2024-03-24T07:58:40.747463Z","shell.execute_reply.started":"2024-03-24T07:56:23.018949Z","shell.execute_reply":"2024-03-24T07:58:40.746542Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"length of dataset is 76436\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Determining Parameters of model\nhere we define the parameters of the model which are:\n* $ \\text{emission matrix B, where } B_i(o_t) = P(o_t|q_i)$\n* $ \\text{transition matrix A, where } A_{i-1,i} = P(q_{i}|q_{i-1})$\n* $ \\text{initial probabilities } \\pi \\text{ where } \\pi_i = \\text{initial probabilities of }i^{th}\\text{label}$\n\n","metadata":{}},{"cell_type":"code","source":"A = defaultdict(lambda:defaultdict(float)) # transition matrix\nB = defaultdict(lambda:defaultdict(float)) # emmision matrix\nPI = defaultdict(float)\n\nfor item in state_seq:\n    for i_1,i in zip(item,item[1:]):\n        A[i_1][i]+=1\n\nfor item in A.keys():\n    for key in A[item].keys():\n        A[item][key] = A[item][key]/tag_count[item]\n    \nPI = A['<s>']\nfor item in tag_zipped_words:\n    for obs,state in list(item):\n        B[state][obs]+=1\nfor item in B.keys():\n    for key in B[item].keys():\n        B[item][key] /= tag_count[item]\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T07:58:40.749329Z","iopub.execute_input":"2024-03-24T07:58:40.749925Z","iopub.status.idle":"2024-03-24T07:58:42.283795Z","shell.execute_reply.started":"2024-03-24T07:58:40.749895Z","shell.execute_reply":"2024-03-24T07:58:42.282890Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Viterbi algorithm","metadata":{}},{"cell_type":"code","source":"def viterbi(sentence):\n    sentence = sentence.strip().split()\n    memo = defaultdict(lambda: defaultdict(tuple))\n    w = sentence[0]\n    for tags in state_tags[w]:\n        memo[0][tags] = (PI[tags],'<s>')\n    for i in range(1,len(sentence)):\n        w = sentence[i]\n        tags = state_tags[w]\n        for tag in tags:\n            emission = B[tag][w]\n            memo[i][tag] = (-1e9,'')\n            for t,(prior,path) in memo[i-1].items():\n                transition = A[t][tag]\n                curr_prob = transition * emission * prior\n                if curr_prob>memo[i][tag][0]:\n                    memo[i][tag] = (curr_prob,f'{path},{tag}')\n    n = len(sentence)\n    res = ''\n    check = -1e9\n    for t,(prior,path) in memo[n-1].items():\n        if prior>check:\n            check = prior\n            res = path\n    return res\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-24T07:58:42.285340Z","iopub.execute_input":"2024-03-24T07:58:42.285675Z","iopub.status.idle":"2024-03-24T07:58:42.298378Z","shell.execute_reply.started":"2024-03-24T07:58:42.285646Z","shell.execute_reply":"2024-03-24T07:58:42.297495Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# demo test","metadata":{}},{"cell_type":"code","source":"viterbi(\"increase the pressure further more to get success\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T07:58:42.301107Z","iopub.execute_input":"2024-03-24T07:58:42.301868Z","iopub.status.idle":"2024-03-24T07:58:42.313508Z","shell.execute_reply.started":"2024-03-24T07:58:42.301826Z","shell.execute_reply":"2024-03-24T07:58:42.312556Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'<s>,DT,NN,RB,JJR,TO,VB,NN'"},"metadata":{}}]},{"cell_type":"markdown","source":"# HMM model\nHere we create an HMM model using pytorch and combine all the previously defined steps in the init method and running the virerbi in the forward method","metadata":{}},{"cell_type":"code","source":"class HMM:\n    def __init__(self, dataset):\n        # data processing\n        self.state_tags = defaultdict(set)\n        self.sentences = []\n        self.state_seq = []\n        self.vocab = set()\n        self.tags = set()\n        self.tag_count = defaultdict(int)\n        self.word_count = defaultdict(int)\n        self.tag_zipped_words = []\n        from copy import deepcopy\n        for item in dataset:\n            self.sentences.append(item['sentence'])\n            self.state_seq.append(item['labels'])\n            self.tag_zipped_words.append(deepcopy(list(zip(item['sentence'], item['labels']))))\n            for word, count in list(Counter(item['sentence']).items()):\n                self.word_count[word] += count\n            for tag, count in list(Counter(item['labels']).items()):\n                self.tag_count[tag] += count\n            self.vocab = self.vocab.union(set(item['sentence']))\n            self.tags = self.tags.union(set(item['labels']))\n            for i, word in enumerate(item['sentence']):\n                self.state_tags[word].add(item['labels'][i])\n        \n        # parameters\n        self.A = defaultdict(lambda: defaultdict(float))  # transition matrix\n        self.B = defaultdict(lambda: defaultdict(float))  # emission matrix\n        self.PI = defaultdict(float)\n\n        for item in self.state_seq:\n            for i_1, i in zip(item, item[1:]):\n                self.A[i_1][i] += 1\n\n        for item in self.A.keys():\n            for key in self.A[item].keys():\n                self.A[item][key] = self.A[item][key] / self.tag_count[item]\n\n        self.PI = self.A['<s>']\n        for item in self.tag_zipped_words:\n            for obs, state in list(item):\n                self.B[state][obs] += 1\n        for item in self.B.keys():\n            for key in self.B[item].keys():\n                self.B[item][key] /= self.tag_count[item]\n\n    def forward(self, sentence):\n        sentence = sentence.strip().split()\n        memo = defaultdict(lambda: defaultdict(tuple))\n        w = sentence[0]\n        for tags in self.state_tags[w]:\n            memo[0][tags] = (self.PI[tags],'<s>')\n        for i in range(1,len(sentence)):\n            w = sentence[i]\n            tags = self.state_tags[w]\n            for tag in tags:\n                emission = self.B[tag][w]\n                memo[i][tag] = (-1e9,'')\n                for t,(prior,path) in memo[i-1].items():\n                    transition = self.A[t][tag]\n                    curr_prob = transition * emission * prior\n                    if curr_prob>memo[i][tag][0]:\n                        memo[i][tag] = (curr_prob,f'{path},{tag}')\n        n = len(sentence)\n        res = ''\n        check = -1e9\n        for t,(prior,path) in memo[n-1].items():\n            if prior>check:\n                check = prior\n                res = path\n        return res\n\n    def __getstate__(self):\n        \"\"\"Prepare for pickling.\"\"\"\n        state = self.__dict__.copy()\n        # Convert defaultdicts to dicts for pickling\n        state['state_tags'] = dict(state['state_tags'])\n        state['A'] = {k: dict(v) for k, v in state['A'].items()}\n        state['B'] = {k: dict(v) for k, v in state['B'].items()}\n        state['PI'] = dict(state['PI'])\n        return state\n\n    def __setstate__(self, state):\n        \"\"\"Reconstruct from pickle.\"\"\"\n        self.__dict__.update(state)\n        # Convert dicts back to defaultdicts if needed\n        self.state_tags = defaultdict(set, self.state_tags)\n        self.A = defaultdict(lambda: defaultdict(float), {k: defaultdict(float, v) for k, v in self.A.items()})\n        self.B = defaultdict(lambda: defaultdict(float), {k: defaultdict(float, v) for k, v in self.B.items()})\n        self.PI = defaultdict(float, self.PI)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T07:58:42.315278Z","iopub.execute_input":"2024-03-24T07:58:42.316050Z","iopub.status.idle":"2024-03-24T07:58:42.342475Z","shell.execute_reply.started":"2024-03-24T07:58:42.316013Z","shell.execute_reply":"2024-03-24T07:58:42.341256Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Training and testing the HMM \ninstantiating the HMM object by passing a training dataset will build the parameter matrices automatically ","metadata":{}},{"cell_type":"code","source":"model = HMM(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T07:58:42.343877Z","iopub.execute_input":"2024-03-24T07:58:42.344182Z","iopub.status.idle":"2024-03-24T08:00:57.389945Z","shell.execute_reply.started":"2024-03-24T07:58:42.344153Z","shell.execute_reply":"2024-03-24T08:00:57.389022Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model.forward('I will work hard to do well ')","metadata":{"execution":{"iopub.status.busy":"2024-03-24T08:00:57.391119Z","iopub.execute_input":"2024-03-24T08:00:57.391491Z","iopub.status.idle":"2024-03-24T08:00:57.399621Z","shell.execute_reply.started":"2024-03-24T08:00:57.391455Z","shell.execute_reply":"2024-03-24T08:00:57.398547Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'<s>,MD,VB,JJ,TO,VB,RB'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Saving The Model","metadata":{}},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/working/hmm_model.pkl','wb') as f:\n    pickle.dump(model,f)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T08:00:57.401148Z","iopub.execute_input":"2024-03-24T08:00:57.401632Z","iopub.status.idle":"2024-03-24T08:00:59.845695Z","shell.execute_reply.started":"2024-03-24T08:00:57.401596Z","shell.execute_reply":"2024-03-24T08:00:59.844481Z"},"trusted":true},"execution_count":24,"outputs":[]}]}