{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data preprocessing\n","here we obtain the data from the json file and then process it by adding start and end tokens to it and then define the vocabulary, sentence list and also the tags (or the state) corresponding to each observation (or words). These will be helpful for us in determining the parameters of **Hidden Markov Model later**"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T07:56:23.018998Z","iopub.status.busy":"2024-03-24T07:56:23.018445Z","iopub.status.idle":"2024-03-24T07:58:40.747463Z","shell.execute_reply":"2024-03-24T07:58:40.746542Z","shell.execute_reply.started":"2024-03-24T07:56:23.018949Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["length of dataset is 38218\n"]}],"source":["import pandas as pd\n","import json\n","from collections import defaultdict,Counter\n","\n","with open('input/train.json','r') as f:\n","    json_data = f.read()\n","val_data = json.load(open('input/dev.json'))\n","\n","dataset = json.loads(json_data)\n","for item in dataset:\n","    item['sentence'].insert(0,'<s>')\n","    item['sentence'].append('</s>')\n","    item['labels'].insert(0,'<s>')\n","    item['labels'].append('</s>')\n","print(f'length of dataset is {len(dataset)}')\n","\n","\n","state_tags = defaultdict(set)\n","sentences = list()\n","state_seq = list()\n","vocab = set()\n","tags = set()\n","tag_count = defaultdict(int)\n","word_count = defaultdict(int)\n","tag_zipped_words = list()\n","from copy import deepcopy\n","for item in dataset:\n","    sentences.append(item['sentence'])\n","    state_seq.append(item['labels'])\n","    tag_zipped_words.append(deepcopy(list(zip(item['sentence'],item['labels']))))\n","    for word,count in list(Counter(item['sentence']).items()):\n","        word_count[word]+=count\n","    for tag,count in list(Counter(item['labels']).items()):\n","        tag_count[tag]+=count   \n","    vocab = vocab.union(set(item['sentence']))\n","    tags = tags.union(set(item['labels']))\n","    for i,word in enumerate(item['sentence']):\n","        state_tags[word].add(item['labels'][i])"]},{"cell_type":"markdown","metadata":{},"source":["# Determining Parameters of model\n","here we define the parameters of the model which are:\n","* $ \\text{emission matrix B, where } B_i(o_t) = P(o_t|q_i)$\n","* $ \\text{transition matrix A, where } A_{i-1,i} = P(q_{i}|q_{i-1})$\n","* $ \\text{initial probabilities } \\pi \\text{ where } \\pi_i = \\text{initial probabilities of }i^{th}\\text{label}$\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T07:58:40.749925Z","iopub.status.busy":"2024-03-24T07:58:40.749329Z","iopub.status.idle":"2024-03-24T07:58:42.283795Z","shell.execute_reply":"2024-03-24T07:58:42.282890Z","shell.execute_reply.started":"2024-03-24T07:58:40.749895Z"},"trusted":true},"outputs":[],"source":["A = defaultdict(lambda:defaultdict(float)) # transition matrix\n","B = defaultdict(lambda:defaultdict(float)) # emmision matrix\n","PI = defaultdict(float)\n","\n","for item in state_seq:\n","    for i_1,i in zip(item,item[1:]):\n","        A[i_1][i]+=1\n","\n","for item in A.keys():\n","    for key in A[item].keys():\n","        A[item][key] = A[item][key]/tag_count[item]\n","    \n","PI = A['<s>']\n","for item in tag_zipped_words:\n","    for obs,state in list(item):\n","        B[state][obs]+=1\n","for item in B.keys():\n","    for key in B[item].keys():\n","        B[item][key] /= tag_count[item]\n","    \n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Viterbi algorithm"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T07:58:42.285675Z","iopub.status.busy":"2024-03-24T07:58:42.285340Z","iopub.status.idle":"2024-03-24T07:58:42.298378Z","shell.execute_reply":"2024-03-24T07:58:42.297495Z","shell.execute_reply.started":"2024-03-24T07:58:42.285646Z"},"trusted":true},"outputs":[],"source":["def viterbi(sentence):\n","    sentence = sentence.strip().split()\n","    memo = defaultdict(lambda: defaultdict(tuple))\n","    w = sentence[0]\n","    for tags in state_tags[w]:\n","        memo[0][tags] = (PI[tags],'<s>')\n","    for i in range(1,len(sentence)):\n","        w = sentence[i]\n","        tags = state_tags[w]\n","        for tag in tags:\n","            emission = B[tag][w]\n","            memo[i][tag] = (-1e9,'')\n","            for t,(prior,path) in memo[i-1].items():\n","                transition = A[t][tag]\n","                curr_prob = transition * emission * prior\n","                if curr_prob>memo[i][tag][0]:\n","                    memo[i][tag] = (curr_prob,f'{path},{tag}')\n","    n = len(sentence)\n","    res = ''\n","    check = -1e9\n","    for t,(prior,path) in memo[n-1].items():\n","        if prior>check:\n","            check = prior\n","            res = path\n","    return res\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# demo test"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T07:58:42.301868Z","iopub.status.busy":"2024-03-24T07:58:42.301107Z","iopub.status.idle":"2024-03-24T07:58:42.313508Z","shell.execute_reply":"2024-03-24T07:58:42.312556Z","shell.execute_reply.started":"2024-03-24T07:58:42.301826Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'<s>,DT,NN,RB,JJR,TO,VB,NN'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["viterbi(\"increase the pressure further more to get success\")"]},{"cell_type":"markdown","metadata":{},"source":["# HMM model\n","Here we create an HMM model using and combine all the previously defined steps in the init method and running the virerbi in the forward method"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T07:58:42.316050Z","iopub.status.busy":"2024-03-24T07:58:42.315278Z","iopub.status.idle":"2024-03-24T07:58:42.342475Z","shell.execute_reply":"2024-03-24T07:58:42.341256Z","shell.execute_reply.started":"2024-03-24T07:58:42.316013Z"},"trusted":true},"outputs":[],"source":["class HMM:\n","    def __init__(self, dataset):\n","        # data processing\n","        self.state_tags = defaultdict(set)\n","        self.sentences = []\n","        self.state_seq = []\n","        self.vocab = set()\n","        self.tags = set()\n","        self.tag_count = defaultdict(int)\n","        self.word_count = defaultdict(int)\n","        self.tag_zipped_words = []\n","        from copy import deepcopy\n","        for item in dataset:\n","            self.sentences.append(item['sentence'])\n","            self.state_seq.append(item['labels'])\n","            self.tag_zipped_words.append(deepcopy(list(zip(item['sentence'], item['labels']))))\n","            for word, count in list(Counter(item['sentence']).items()):\n","                self.word_count[word] += count\n","            for tag, count in list(Counter(item['labels']).items()):\n","                self.tag_count[tag] += count\n","            self.vocab = self.vocab.union(set(item['sentence']))\n","            self.tags = self.tags.union(set(item['labels']))\n","            for i, word in enumerate(item['sentence']):\n","                self.state_tags[word].add(item['labels'][i])\n","        \n","        # parameters\n","        self.A = defaultdict(lambda: defaultdict(float))  # transition matrix\n","        self.B = defaultdict(lambda: defaultdict(float))  # emission matrix\n","        self.PI = defaultdict(float)\n","\n","        for item in self.state_seq:\n","            for i_1, i in zip(item, item[1:]):\n","                self.A[i_1][i] += 1\n","\n","        for item in self.A.keys():\n","            for key in self.A[item].keys():\n","                self.A[item][key] = self.A[item][key] / self.tag_count[item]\n","\n","        self.PI = self.A['<s>']\n","        for item in self.tag_zipped_words:\n","            for obs, state in list(item):\n","                self.B[state][obs] += 1\n","        for item in self.B.keys():\n","            for key in self.B[item].keys():\n","                self.B[item][key] /= self.tag_count[item]\n","\n","    def forward(self, sentence):\n","        sentence = sentence.strip().split()\n","        memo = defaultdict(lambda: defaultdict(tuple))\n","        w = sentence[0]\n","        for tags in self.state_tags[w]:\n","            memo[0][tags] = (self.PI[tags],'<s>')\n","        for i in range(1,len(sentence)):\n","            w = sentence[i]\n","            tags = self.state_tags[w]\n","            for tag in tags:\n","                emission = self.B[tag][w]\n","                memo[i][tag] = (-1e9,'')\n","                for t,(prior,path) in memo[i-1].items():\n","                    transition = self.A[t][tag]\n","                    curr_prob = transition * emission * prior\n","                    if curr_prob>memo[i][tag][0]:\n","                        memo[i][tag] = (curr_prob,f'{path},{tag}')\n","        n = len(sentence)\n","        res = ''\n","        check = -1e9\n","        for t,(prior,path) in memo[n-1].items():\n","            if prior>check:\n","                check = prior\n","                res = path\n","        return res\n","\n","    def __getstate__(self):\n","        \"\"\"Prepare for pickling.\"\"\"\n","        state = self.__dict__.copy()\n","        # Convert defaultdicts to dicts for pickling\n","        state['state_tags'] = dict(state['state_tags'])\n","        state['A'] = {k: dict(v) for k, v in state['A'].items()}\n","        state['B'] = {k: dict(v) for k, v in state['B'].items()}\n","        state['PI'] = dict(state['PI'])\n","        return state\n","\n","    def __setstate__(self, state):\n","        \"\"\"Reconstruct from pickle.\"\"\"\n","        self.__dict__.update(state)\n","        # Convert dicts back to defaultdicts if needed\n","        self.state_tags = defaultdict(set, self.state_tags)\n","        self.A = defaultdict(lambda: defaultdict(float), {k: defaultdict(float, v) for k, v in self.A.items()})\n","        self.B = defaultdict(lambda: defaultdict(float), {k: defaultdict(float, v) for k, v in self.B.items()})\n","        self.PI = defaultdict(float, self.PI)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training and testing the HMM \n","instantiating the HMM object by passing a training dataset will build the parameter matrices automatically "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T07:58:42.344182Z","iopub.status.busy":"2024-03-24T07:58:42.343877Z","iopub.status.idle":"2024-03-24T08:00:57.389945Z","shell.execute_reply":"2024-03-24T08:00:57.389022Z","shell.execute_reply.started":"2024-03-24T07:58:42.344153Z"},"trusted":true},"outputs":[],"source":["model = HMM(dataset)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T08:00:57.391491Z","iopub.status.busy":"2024-03-24T08:00:57.391119Z","iopub.status.idle":"2024-03-24T08:00:57.399621Z","shell.execute_reply":"2024-03-24T08:00:57.398547Z","shell.execute_reply.started":"2024-03-24T08:00:57.391455Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['MD', 'VB', 'JJ', 'TO', 'VB', 'RB']"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model.forward('I will work hard to do well ').split(',')[1:]"]},{"cell_type":"markdown","metadata":{},"source":["# Saving The Model"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T08:00:57.401632Z","iopub.status.busy":"2024-03-24T08:00:57.401148Z","iopub.status.idle":"2024-03-24T08:00:59.845695Z","shell.execute_reply":"2024-03-24T08:00:59.844481Z","shell.execute_reply.started":"2024-03-24T08:00:57.401596Z"},"trusted":true},"outputs":[],"source":["import pickle\n","with open('/kaggle/working/hmm_model.pkl','wb') as f:\n","    pickle.dump(model,f)"]},{"cell_type":"markdown","metadata":{},"source":["# Checking Metrics"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ipsit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\ipsit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\ipsit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\ipsit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"name":"stdout","output_type":"stream","text":["F1 Score: 0.523539597302735\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","                   0.00      0.00      0.00         0\n","           $       0.56      0.56      0.56       156\n","          ''       0.92      0.91      0.91       168\n","           ,       0.00      0.00      0.00      1021\n","       -LRB-       0.33      0.21      0.26        19\n","       -RRB-       0.74      0.74      0.74        19\n","           .       1.00      1.00      1.00       945\n","           :       0.64      0.62      0.63        85\n","          CC       0.69      0.60      0.64       519\n","          CD       0.61      0.61      0.61       767\n","          DT       0.55      0.47      0.51      2003\n","          EX       0.64      0.52      0.57        27\n","          FW       0.00      0.00      0.00         0\n","          IN       0.52      0.46      0.49      2377\n","          JJ       0.46      0.50      0.48      1386\n","         JJR       0.57      0.55      0.56       125\n","         JJS       0.44      0.39      0.41        49\n","          LS       0.00      0.00      0.00         0\n","          MD       0.56      0.54      0.55       247\n","          NN       0.54      0.54      0.54      3172\n","         NNP       0.67      0.60      0.63      1511\n","        NNPS       0.32      0.33      0.32        46\n","         NNS       0.53      0.51      0.52      1448\n","         PDT       0.55      0.60      0.57        10\n","         POS       0.48      0.48      0.48       189\n","         PRP       0.61      0.55      0.58       467\n","        PRP$       0.52      0.50      0.51       212\n","          RB       0.53      0.47      0.50       820\n","         RBR       0.22      0.27      0.24        41\n","         RBS       0.23      0.23      0.23        13\n","          RP       0.20      0.42      0.27        65\n","         SYM       0.00      0.00      0.00         0\n","          TO       0.55      0.52      0.53       556\n","          UH       0.00      0.00      0.00         0\n","          VB       0.49      0.48      0.48       688\n","         VBD       0.49      0.47      0.48       824\n","         VBG       0.54      0.48      0.51       336\n","         VBN       0.50      0.49      0.49       501\n","         VBP       0.38      0.41      0.39       306\n","         VBZ       0.52      0.53      0.53       489\n","         WDT       0.64      0.69      0.66        86\n","          WP       0.53      0.48      0.50        42\n","         WP$       1.00      1.00      1.00         2\n","         WRB       0.61      0.49      0.55        55\n","          ``       0.62      0.28      0.39       169\n","\n","    accuracy                           0.51     21961\n","   macro avg       0.48      0.45      0.46     21961\n","weighted avg       0.54      0.51      0.52     21961\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\ipsit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","c:\\Users\\ipsit\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["from sklearn.metrics import classification_report, f1_score\n","import pickle\n","from collections import defaultdict\n","predicted_tags = list()\n","true_tags = list()\n","count = 0\n","total = 0\n","with open('hmm_model.pkl', 'rb') as f:\n","    model = pickle.load(f)\n","for element in val_data:\n","    sentence = ' '.join(element['sentence'])\n","    pred_tag = model.forward(sentence).split(',')[1:]\n","    if len(element[\"labels\"])==len(pred_tag):\n","        predicted_tags.append(pred_tag)\n","        true_tags.append(element['labels'])\n","# Flatten the lists of lists into a single list for evaluation\n","true_tags_flat = [tag for sent in true_tags for tag in sent]\n","predicted_tags_flat = [tag for sent in predicted_tags for tag in sent]\n","\n","# Calculate the F1 score\n","f1 = f1_score(true_tags_flat, predicted_tags_flat, average='weighted')\n","\n","# Print the classification report for a detailed breakdown\n","report = classification_report(true_tags_flat, predicted_tags_flat)\n","\n","print(f'F1 Score: {f1}')\n","print('Classification Report:')\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3919443,"sourceId":6813582,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
